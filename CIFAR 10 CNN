#Weston Harby
#deep learning model for CIFAR 10 dataset
#tensorflow 2.0 alpha
#achieves ~75% accuracy on test data after 50 epcohs with a batch size of 256
#training takes 10 seconds per epoch witha 1080 ti


#package import 
import tensorflow
import numpy as np
import os
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.models import model_from_json
import random

(x_train, y_train), (x_test, y_test) = cifar10.load_data()

x_train = x_train.astype('float32')
x_test = x_test.astype('float32')

x_test /= 255
x_train /= 255

y_train = tensorflow.keras.utils.to_categorical(y_train, 10)
y_test = tensorflow.keras.utils.to_categorical(y_test, 10)

model = Sequential()

def MNIST_train(batch_size, epochs):
    model.add(Conv2D(256, (3,3), input_shape=(32,32,3,), activation='elu'))
    model.add(Conv2D(128, (3,3), activation='elu'))

    model.add(MaxPooling2D())

    model.add(Conv2D(128, (2,2), activation='elu'))
    model.add(Conv2D(64, (2,2), activation='elu'))

    model.add(MaxPooling2D())

    model.add(Conv2D(128, (2,2), activation='elu'))
    model.add(Conv2D(64, (2,2), activation='elu'))

    model.add(MaxPooling2D())

    model.add(Flatten())

    model.add(Dense(512, activation='sigmoid'))
    model.add(Dropout(.2))
    model.add(Dense(100, activation='sigmoid'))
    model.add(Dropout(.2))
    model.add(Dense(10, activation='softmax'))

    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])
    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)

    model_json = model.to_json()
    with open("model.json", "w") as json_file:
        json_file.write(model_json)

    model.save_weights("model.h5")
    print("trained model saved to disk")
    json_file = open('model.json', 'r')
    loaded_model_json = json_file.read()
    loaded_model = model_from_json(loaded_model_json)
    loaded_model.load_weights("model.h5")
    json_file.close()
    print("trained model loaded from disk")

    loaded_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])
    loaded_model.evaluate(x_test, y_test)

    loaded_model.predict(x_test[934])

MNIST_train(256, 50)
